---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Ph.D. researcher in robotics and autonomous systems at _Nanyang Technological University_, working at the intersection of trustworthy AI, autonomous driving, and human–machine collaboration. My research focuses on building intelligent systems that remain safe, robust, and cooperative under uncertainty, adversarial conditions, and real-world constraints.

My doctoral research focuses on trustworthy self-driving systems, including adversarial scene generation, online monitoring, and decision-making under uncertainty. Rather than optimizing average performance, I focus on exposing, monitoring, and managing failure modes.

Before my Ph.D., I worked as a software engineer at _Zhongxing Telecommunication Equipment_, developing high-frequency algorithms (240kHz) for 5G systems. This experience shaped my engineering approach: AI systems must be deployable, resource-aware, and verifiable.

In parallel, I have worked on soft robotics, exoskeletons, and human–robot interfaces, which strongly influence how I view AI as an embodied, interactive system rather than a standalone model.

## An Approach to Trustworthy AI
My research philosophy is centered on **adversarial design**. Trustworthy AI is not achieved by average-case performance, but by continuously exposing and managing failure modes.
<p align="center"> <img src="assets/img/Philo.jpg" alt="Adversarial design philosophy illustration" width="400"/> </p>
**Adversary** actively generates rare, risky, and adversarial scenarios to expose system weaknesses, using passive and active testing as well as objective and subjective evaluations. **Adaptor** continuously improves perception, decision-making, and control to mitigate the failures revealed by adversarial exposure. **Collaborator (Human-in-the-loop)** provides human assistance when uncertainty, ambiguity, or risk exceeds the autonomous system’s capability.
